# # # #
# ERMS TANCADA CORE
# # # #
Bacon(core = "ErmsTancada", coredir = "Data/RadiocarbonData/", acc.shape = 1.5, acc.mean = 50)
# # # #
# ERMS TANCADA CORE
# # # #
Bacon(core = "ErmsTancada", coredir = "Data/RadiocarbonData/", acc.shape = 1.5, acc.mean = 50, postbomb = 1)
# Libraries
library(rbacon)
# # # #
# ERMS TANCADA CORE
# # # #
Bacon(core = "ErmsTancada", coredir = "Data/RadiocarbonData/", acc.shape = 1.5, acc.mean = 50, postbomb = 1)
# # # #
# ERMS TANCADA CORE
# # # #
Bacon(core = "ErmsTancada", coredir = "Data/RadiocarbonData/", acc.shape = 1.5, acc.mean = 50, postbomb = 1)
# Libraries
library(tidyverse)
library(tidylog)
library(cowplot)
library(magick)
library(robCompositions)
library(ggsci)
library(RColorBrewer)
# Data input.
# Go to 1_XRF_processing.R and choose the file_name to be loaded.
#
# # #
# # ! # #
# # # # # #
#
#
# Save changes to 1_XRF_processing.R before running source(1_XRF_processing.R)
source("1_XRF_processing.R")
# File_name to be used for printing figures
file_name <- "ErmsTancada"
ggplot(XRFdata_tidy_filtered) +
geom_line(aes(x = -Sample, y = Area, col = Section), lwd = 0.3) +
xlab("Depth (mm)") +
ylab("Counts per second") +
coord_flip() +
ggtitle(label = file_name) +
facet_wrap(~Element, scales = "free") +
theme_bw() +
theme(legend.position = 'none')
# We check if there are any zeros or negative values. Compositional data must be positive,
# according to the book Applied Compositional Data Analysis, by Filzmoser et al. 2018.
XRFdata_wide <- XRFdata_tidy_filtered %>%
mutate(Area = ifelse(Area < 100, NA, Area)) %>%
select(-Chi, -Std) %>%
pivot_wider(names_from = Element, values_from = Area) %>%  # This makes the data set wide again, to compute PCA more easily
na.omit()
# robCompositions uses data.frames instead of tibbles. Let's use convert the dataset into a data.frame
XRFdata_wide_df <- XRFdata_wide %>%
select(-CoreID, -Section, -Sample, -Red, -Green, -Blue, -a, -l, -b)
XRFdata_wide_df <- as.data.frame(XRFdata_wide_df)
rownames(XRFdata_wide_df) <- XRFdata_wide$Sample
# Compositional PCA, non-robust, for comparison.
p_comp <- pcaCoDa(XRFdata_wide_df, method = "classical")
# Compositional PCA, robust. The good one.
set.seed(234)
p_comp_rob <- pcaCoDa(XRFdata_wide_df, method = "robust")
summary(p_comp_rob)
plot(p_comp_rob, type = "l") # 3 components seem to be needed.
# We extract the % variance explained
variance_explained <- p_comp_rob$eigenvalues/sum(p_comp_rob$eigenvalues)
# We choose the number of components using a cutoff: a PC will be chosen if it explains
# more than what 2 variables would explain by chance (2/number of columns)
components <- filter(enframe(variance_explained), variance_explained > 2/length(names(XRFdata_wide_df)))
AutVal <- length(components$name)
par(mfrow = c(1,2))
biplot(p_comp, xlabs = rownames(XRFdata_wide_df))
biplot(p_comp_rob, xlabs = rownames(XRFdata_wide_df))
# We first extract the loadings for the components of interest from p_comp_rob
dbloadings <- as.data.frame(p_comp_rob$loadings[,1:AutVal])
# Then we extract the scores for the components of interest from p_comp_rob
dbscores <- as.data.frame(p_comp_rob$scores[,1:AutVal])
dbscores$Sample <- XRFdata_wide$Sample
dbscores$Section <- as.factor(XRFdata_wide$Section)
# Biplot for PC1 vs PC2
ggplot(data = dbloadings)+
geom_point(data = dbscores, aes(x = Comp.1, y = Comp.2, colour = Section)) +
# coord_fixed(ratio = 1) +
annotate(geom = "text",
x = (dbloadings$Comp.1*3.4),
y = (dbloadings$Comp.2*3.4),
label = rownames(dbloadings),
col = "black") +
xlab(paste("PC1 (", round(variance_explained[1]*100), "%)", sep = "")) +
ylab(paste("PC2 (", round(variance_explained[2]*100), "%)", sep = "")) +
geom_segment(data = dbloadings,
aes(x =0 , y = 0, xend = Comp.1*3, yend = Comp.2*3),
arrow = arrow(length = unit(1/2, 'picas')),
color = "black", linetype = 'solid', size = 0.5) +
ggtitle(label = file_name) +
scale_color_d3(palette = "category20") +
theme_bw(base_size = 20,
base_line_size = 0.5) +
theme(legend.position="none")
# Biplot for PC1 vs PC2
ggplot(data = dbloadings)+
geom_point(data = dbscores, aes(x = Comp.1, y = Comp.2, colour = Section)) +
# coord_fixed(ratio = 1) +
annotate(geom = "text",
x = (dbloadings$Comp.1*3.4),
y = (dbloadings$Comp.2*3.4),
label = rownames(dbloadings),
col = "black") +
xlab(paste("PC1 (", round(variance_explained[1]*100), "%)", sep = "")) +
ylab(paste("PC2 (", round(variance_explained[2]*100), "%)", sep = "")) +
geom_segment(data = dbloadings,
aes(x =0 , y = 0, xend = Comp.1*3, yend = Comp.2*3),
arrow = arrow(length = unit(1/2, 'picas')),
color = "black", linetype = 'solid', size = 0.5) +
ggtitle(label = file_name) +
scale_color_d3(palette = "category20") +
theme_bw(base_size = 20,
base_line_size = 0.5) +
theme()
# Biplot for PC1 vs PC2
ggplot(data = dbloadings)+
geom_point(data = dbscores, aes(x = Comp.1, y = Comp.2, colour = Section)) +
# coord_fixed(ratio = 1) +
annotate(geom = "text",
x = (dbloadings$Comp.1*3.4),
y = (dbloadings$Comp.2*3.4),
label = rownames(dbloadings),
col = "black") +
xlab(paste("PC1 (", round(variance_explained[1]*100), "%)", sep = "")) +
ylab(paste("PC2 (", round(variance_explained[2]*100), "%)", sep = "")) +
geom_segment(data = dbloadings,
aes(x =0 , y = 0, xend = Comp.1*3, yend = Comp.2*3),
arrow = arrow(length = unit(1/2, 'picas')),
color = "black", linetype = 'solid', size = 0.5) +
ggtitle(label = file_name) +
scale_color_d3(palette = "category20") +
theme_bw(base_size = 20,
base_line_size = 0.5) +
theme(legend.position="none")
names(dbloadings) <- c("PC1", "PC2")
dbloadings$Elements <- rownames(dbloadings)
dbloadings %>%
pivot_longer(cols = starts_with("PC"), names_to = "components", values_to = "loadings") %>%
ggplot(aes(x = Elements, y = components)) +
geom_tile(aes(fill = loadings)) +
scale_fill_gradient2(low = "#2467AD", high = "#B2182B", mid = "white", midpoint = 0) +
xlab("") +
ylab("") +
ggtitle(label = file_name) +
coord_fixed(ratio = 1) +
theme_bw(base_size = 17,
base_line_size = 0.5)
names(dbscores) <- c("PC1", "PC2", "Sample", "Section")
dbscores_plot <- dbscores %>%
left_join(XRFdata_wide, by = "Sample") %>%
select(starts_with("PC"), "Sample", "Section.x", "CoreID", "l") %>%
pivot_longer(cols = c(starts_with("PC"), l), names_to = "Components", values_to = "Scores") %>%
mutate(Sample = Sample-min(Sample), # to make the plot start at 0 cm, approximately where the 1st XRF measurement was taken
Sample_cm = Sample/10,
labs = ifelse(Components == "PC1",
paste("PC1 (", round(variance_explained[1]*100), "%)", sep = ""),
ifelse(Components == "PC2",
paste("PC2 (", round(variance_explained[2]*100), "%)", sep = ""),
"Core lightness"))) %>%
mutate(labs = factor(labs,
levels = c(paste("PC1 (", round(variance_explained[1]*100), "%)", sep = ""),
paste("PC2 (", round(variance_explained[2]*100), "%)", sep = ""),
"Core lightness")))
# We find the points where we change section using diff. We divide by 10 to get it in cm instead of mm.
section_break <- dbscores_plot$Sample[which(diff(as.numeric(dbscores_plot$Section.x)) == 1)]/10
p <- ggplot(dbscores_plot, aes(x = -Sample_cm, y = Scores)) +
# geom_point(aes(colour = Components)) +
geom_line(colour = "#757575", lwd = 0.3) +
geom_smooth(aes(colour = Components, fill = Components), span = 0.08) +
scale_colour_manual(values = c("#1E6DA8","#FE7223", "#2C9431")) +
scale_fill_manual(values = c("#1E6DA8","#FE7223", "#2C9431")) +
geom_vline(aes(xintercept = -section_break), lty = 2, colour = "darkgrey") +
# geom_vline(aes(xintercept = -section_break[1]), lty = 2, colour = "darkgrey") + # For PanissosBIS
# geom_vline(aes(xintercept = -section_break[2]), lty = 2, colour = "darkgrey") + # For PanissosBIS
# scale_color_d3(palette = "category20") +
xlab("Core depth (cm)") +
ylab("") +
facet_wrap(~labs, scales = "free") +
ggtitle(label = file_name) +
coord_flip() +
theme_bw(base_size = 17,
base_line_size = 0.5) +
theme(legend.position = "none")
ggdraw(p) +
draw_label("Scores (clr-robust)", x = 0.215, y = 0.03) +
draw_label("Scores (clr-robust)", x = 0.54, y = 0.03) +
draw_label("Lightness (%)", x = 0.865, y = 0.03)
library(tidyverse)
library(tidylog)
library(cowplot)
library(magick)
# Auxiliary functions
source("Functions_for_XRF.R")
# XRF data input
file_name <- "ERMSTANCADA1&2_edited.csv"
# file_name <- "LLANADA1&2_edited.csv"
# file_name <- "PANISSOS1BIS,2BIS,3BISa_edited.csv"
# file_name <- "SECANELLA1&2a_edited.csv"
# file_name <- "ENCANYISSADA1a_edited.csv"
XRFdata <- read_csv(file = paste("Data/XRF_data/", file_name, sep = ""))
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# 1) Checking data quality - Coefficients of variation using replicates ----
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# 3 replicates were taken every 30 samples during XRF core-scanning
index <- duplicated(XRFdata$Sample) | duplicated(XRFdata$Sample, fromLast = TRUE)
XRFdata_replicates <- XRFdata[which(index == T),]
library(tidyverse)
library(tidylog)
library(cowplot)
library(magick)
# Auxiliary functions
source("Functions_for_XRF.R")
# XRF data input
file_name <- "ERMSTANCADA1&2_edited.csv"
# file_name <- "LLANADA1&2_edited.csv"
# file_name <- "PANISSOS1BIS,2BIS,3BISa_edited.csv"
# file_name <- "SECANELLA1&2a_edited.csv"
# file_name <- "ENCANYISSADA1a_edited.csv"
XRFdata <- read_csv(file = paste("Data/XRF_data/", file_name, sep = ""))
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# 1) Checking data quality - Coefficients of variation using replicates ----
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# 3 replicates were taken every 30 samples during XRF core-scanning
index <- duplicated(XRFdata$Sample) | duplicated(XRFdata$Sample, fromLast = TRUE)
XRFdata_replicates <- XRFdata[which(index == T),]
library(tidyverse)
library(tidylog)
library(cowplot)
library(magick)
# Auxiliary functions
source("Functions_for_XRF.R")
# XRF data input
file_name <- "ERMSTANCADA1&2_edited.csv"
# file_name <- "LLANADA1&2_edited.csv"
# file_name <- "PANISSOS1BIS,2BIS,3BISa_edited.csv"
# file_name <- "SECANELLA1&2a_edited.csv"
# file_name <- "ENCANYISSADA1a_edited.csv"
XRFdata <- read_csv(file = paste("Data/XRF_data/", file_name, sep = ""))
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# 1) Checking data quality - Coefficients of variation using replicates ----
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# 3 replicates were taken every 30 samples during XRF core-scanning
index <- duplicated(XRFdata$Sample) | duplicated(XRFdata$Sample, fromLast = TRUE)
XRFdata_replicates <- XRFdata[which(index == T),]
View(XRFdata_replicates)
discarded_by_cv_replic <- XRFdata_replicates %>%
select(-CoreID, -Section) %>%
select(Sample, ends_with("Area")) %>%
group_by(Sample) %>%
summarise_all(cv) %>%
pivot_longer(cols = -Sample,
names_to = "Element") %>%
group_by(Element) %>%
summarise(mean_cv = mean(value)) %>%
filter(mean_cv>15.2 | mean_cv<0) %>%
mutate(Element_short = str_extract(Element, pattern = "[^-]*")) %>%
select(Element_short)
View(discarded_by_cv_replic)
# We delete coherence/incoherence data to simplify working with the data set.
# REMEMBER TO CHECK COH-INCOH ratio afterwards!
XRFdata <- XRFdata %>%
select(-starts_with("Rh"))
# XRFdata data set is not TIDY! Why? Because we should have 1 column for variable AREA,
# 1 for CHI and one for STD. And then rows for each element.
# Let's make it TIDY with pivot_longer(). When we do pivot tables, we lose the replicates for XRF data, because
# pivot_ functions don't allow rows with the same values in all columns.
XRFdata_tidy <- XRFdata %>%
pivot_longer(cols = c(-CoreID, -Sample, -Section),
names_to = c("Element", "Rest"),
names_sep = "-") %>%
mutate(Rest = recode(Rest,
KaChi2 = "Chi",
KbChi2 = "Chi",
LaChi2 = "Chi",
KaArea = "Area",
KbArea = "Area",
LaArea = "Area",
KaAreaStd = "Std",
KbAreaStd = "Std",
LaAreaStd = "Std")) %>%
pivot_wider(names_from = Rest, values_from = value, values_fn = list(value = mean))
# To check that our results give exactly the same using the tidy or untidy version of the data set
# we plot the Aluminium for example.
XRFdata_tidy %>%
filter(Element == "S") %>%
ggplot() +
geom_line(aes(x = Sample, y = Area))
XRFdata %>%
select(`S-KaArea`, Sample) %>%
ggplot() +
geom_line(aes(x = Sample, y = `S-KaArea`))
# Coefficients of variation for each sample
# The coefficient of variation, is just the sd/mean, and this is what we have for each sample (each cm of the core),
# because for each element we have an AREA (=mean) and an STD (=sd).
discarded_by_cv_sample <- XRFdata_tidy %>%
mutate(cv_sample = (Std/Area)*100) %>%
group_by(Element) %>%
summarise(n = n(),
mean_cv = mean(cv_sample, na.rm = TRUE)) %>%
filter(mean_cv<0 | mean_cv>15) %>%
select(Element)
XRFdata_tidy %>%
ggplot() +
geom_line(aes(x = -Sample, y = Area)) +
coord_flip() +
facet_wrap(~Element, scales = "free")
discarded_by_counts <- XRFdata_tidy %>%
group_by(Element) %>%
summarise(mean_area = mean(Area, na.rm = T),
max_area = max(Area, na.rm = T),
median_area = median(Area, na.rm = T)) %>%
filter(mean_area<1200) %>%
select(Element)
# Lists of problematic elements according to each quality check
discarded_by_cv_replic$Element_short
discarded_by_cv_sample$Element
discarded_by_counts$Element
# Loop to get a list of elements that have been labelled as problematic by ALL quality checkings above
All_elements <- unique(XRFdata_tidy$Element)
discarded_elements <- NULL
for(i in 1:length(All_elements)){
if(!is.na(match(All_elements[i], discarded_by_cv_replic$Element_short)) |
!is.na(match(All_elements[i], discarded_by_cv_sample$Element)) |
!is.na(match(All_elements[i], discarded_by_counts$Element))){
discarded_elements <- c(discarded_elements, All_elements[i])
}
}
discarded_elements
sort(discarded_elements)
# We plot all the elements with good quality
if(file_name == "LLANADA1&2_edited.csv"){
XRFdata_tidy_filtered <- XRFdata_tidy %>%
filter(Element %!in% c("Ar", "As", "Au", "Cl", "Cr", "Cu", "Ga", "Mo", "Nb", "Ni", "P", "Pb", "Se", "V", "Zn")) # Llanada
}
if(file_name == "SECANELLA1&2a_edited.csv"){
XRFdata_tidy_filtered <- XRFdata_tidy %>%
filter(Element %!in% c("Ar", "As", "Au", "Br", "Cl", "Cr", "Cu", "Ga", "Mo", "Nb", "Ni", "P", "Pb", "S","Se", "V", "Zn")) # Secanella
}
if(file_name != "SECANELLA1&2a_edited.csv" & file_name != "LLANADA1&2_edited.csv"){
XRFdata_tidy_filtered <- XRFdata_tidy %>%
filter(Element %!in% discarded_elements) # AUTOMATIC list
}
# Colour data input
colour_data <- read_csv(file = paste("Data/Colour_data/", file_name, sep = ""))
# Summarising colour data for each centimeter, to be able to join colour_data with XRFdata
colour_data_summary <- colour_data %>%
mutate(Sample_cm = round(Sample/10)*10) %>%
group_by(Sample_cm) %>%
summarise(Red = mean(Red),
Green = mean(Green),
Blue = mean(Blue),
l = mean(l),
a = mean(a),
b = mean(b))
# Joining colour_data to XRFdata_tidy_filtered
XRFdata_tidy_filtered <- XRFdata_tidy_filtered %>%
left_join(colour_data_summary, by = c("Sample" = "Sample_cm"))
View(XRFdata_tidy_filtered)
# Clear those data sets that I won't need.
rm(list = c("file_name", "discarded_by_counts", "discarded_by_cv_replic", "discarded_by_cv_sample",
"XRFdata", "XRFdata_replicates", "All_elements", "i", "index", "XRFdata_tidy",
"discarded_elements", "colour_data_summary", "colour_data"))
# Libraries
library(tidyverse)
library(tidylog)
library(cowplot)
library(magick)
library(robCompositions)
library(ggsci)
library(RColorBrewer)
# Data input.
# Go to 1_XRF_processing.R and choose the file_name to be loaded.
#
# # #
# # ! # #
# # # # # #
#
#
# Save changes to 1_XRF_processing.R before running source(1_XRF_processing.R)
source("1_XRF_processing.R")
# File_name to be used for printing figures
file_name <- "ErmsTancada"
ggplot(XRFdata_tidy_filtered) +
geom_line(aes(x = -Sample, y = Area, col = Section), lwd = 0.3) +
xlab("Depth (mm)") +
ylab("Counts per second") +
coord_flip() +
ggtitle(label = file_name) +
facet_wrap(~Element, scales = "free") +
theme_bw() +
theme(legend.position = 'none')
# We check if there are any zeros or negative values. Compositional data must be positive,
# according to the book Applied Compositional Data Analysis, by Filzmoser et al. 2018.
XRFdata_wide <- XRFdata_tidy_filtered %>%
mutate(Area = ifelse(Area < 100, NA, Area)) %>%
select(-Chi, -Std) %>%
pivot_wider(names_from = Element, values_from = Area) %>%  # This makes the data set wide again, to compute PCA more easily
na.omit()
# robCompositions uses data.frames instead of tibbles. Let's use convert the dataset into a data.frame
XRFdata_wide_df <- XRFdata_wide %>%
select(-CoreID, -Section, -Sample, -Red, -Green, -Blue, -a, -l, -b)
XRFdata_wide_df <- as.data.frame(XRFdata_wide_df)
rownames(XRFdata_wide_df) <- XRFdata_wide$Sample
# Compositional PCA, non-robust, for comparison.
p_comp <- pcaCoDa(XRFdata_wide_df, method = "classical")
# Compositional PCA, robust. The good one.
set.seed(234)
p_comp_rob <- pcaCoDa(XRFdata_wide_df, method = "robust")
summary(p_comp_rob)
plot(p_comp_rob, type = "l") # 3 components seem to be needed.
# We extract the % variance explained
variance_explained <- p_comp_rob$eigenvalues/sum(p_comp_rob$eigenvalues)
# We choose the number of components using a cutoff: a PC will be chosen if it explains
# more than what 2 variables would explain by chance (2/number of columns)
components <- filter(enframe(variance_explained), variance_explained > 2/length(names(XRFdata_wide_df)))
AutVal <- length(components$name)
par(mfrow = c(1,2))
biplot(p_comp, xlabs = rownames(XRFdata_wide_df))
biplot(p_comp_rob, xlabs = rownames(XRFdata_wide_df))
# We first extract the loadings for the components of interest from p_comp_rob
dbloadings <- as.data.frame(p_comp_rob$loadings[,1:AutVal])
# Then we extract the scores for the components of interest from p_comp_rob
dbscores <- as.data.frame(p_comp_rob$scores[,1:AutVal])
dbscores$Sample <- XRFdata_wide$Sample
dbscores$Section <- as.factor(XRFdata_wide$Section)
# Biplot for PC1 vs PC2
ggplot(data = dbloadings)+
geom_point(data = dbscores, aes(x = Comp.1, y = Comp.2, colour = Section)) +
# coord_fixed(ratio = 1) +
annotate(geom = "text",
x = (dbloadings$Comp.1*3.4),
y = (dbloadings$Comp.2*3.4),
label = rownames(dbloadings),
col = "black") +
xlab(paste("PC1 (", round(variance_explained[1]*100), "%)", sep = "")) +
ylab(paste("PC2 (", round(variance_explained[2]*100), "%)", sep = "")) +
geom_segment(data = dbloadings,
aes(x =0 , y = 0, xend = Comp.1*3, yend = Comp.2*3),
arrow = arrow(length = unit(1/2, 'picas')),
color = "black", linetype = 'solid', size = 0.5) +
ggtitle(label = file_name) +
scale_color_d3(palette = "category20") +
theme_bw(base_size = 20,
base_line_size = 0.5) +
theme(legend.position="none")
names(dbloadings) <- c("PC1", "PC2")
dbloadings$Elements <- rownames(dbloadings)
dbloadings %>%
pivot_longer(cols = starts_with("PC"), names_to = "components", values_to = "loadings") %>%
ggplot(aes(x = Elements, y = components)) +
geom_tile(aes(fill = loadings)) +
scale_fill_gradient2(low = "#2467AD", high = "#B2182B", mid = "white", midpoint = 0) +
xlab("") +
ylab("") +
ggtitle(label = file_name) +
coord_fixed(ratio = 1) +
theme_bw(base_size = 17,
base_line_size = 0.5)
names(dbscores) <- c("PC1", "PC2", "Sample", "Section")
dbscores_plot <- dbscores %>%
left_join(XRFdata_wide, by = "Sample") %>%
select(starts_with("PC"), "Sample", "Section.x", "CoreID", "l") %>%
pivot_longer(cols = c(starts_with("PC"), l), names_to = "Components", values_to = "Scores") %>%
mutate(Sample = Sample-min(Sample), # to make the plot start at 0 cm, approximately where the 1st XRF measurement was taken
Sample_cm = Sample/10,
labs = ifelse(Components == "PC1",
paste("PC1 (", round(variance_explained[1]*100), "%)", sep = ""),
ifelse(Components == "PC2",
paste("PC2 (", round(variance_explained[2]*100), "%)", sep = ""),
"Core lightness"))) %>%
mutate(labs = factor(labs,
levels = c(paste("PC1 (", round(variance_explained[1]*100), "%)", sep = ""),
paste("PC2 (", round(variance_explained[2]*100), "%)", sep = ""),
"Core lightness")))
# We find the points where we change section using diff. We divide by 10 to get it in cm instead of mm.
section_break <- dbscores_plot$Sample[which(diff(as.numeric(dbscores_plot$Section.x)) == 1)]/10
p <- ggplot(dbscores_plot, aes(x = -Sample_cm, y = Scores)) +
# geom_point(aes(colour = Components)) +
geom_line(colour = "#757575", lwd = 0.3) +
geom_smooth(aes(colour = Components, fill = Components), span = 0.08) +
scale_colour_manual(values = c("#1E6DA8","#FE7223", "#2C9431")) +
scale_fill_manual(values = c("#1E6DA8","#FE7223", "#2C9431")) +
geom_vline(aes(xintercept = -section_break), lty = 2, colour = "darkgrey") +
# geom_vline(aes(xintercept = -section_break[1]), lty = 2, colour = "darkgrey") + # For PanissosBIS
# geom_vline(aes(xintercept = -section_break[2]), lty = 2, colour = "darkgrey") + # For PanissosBIS
# scale_color_d3(palette = "category20") +
xlab("Core depth (cm)") +
ylab("") +
facet_wrap(~labs, scales = "free") +
ggtitle(label = file_name) +
coord_flip() +
theme_bw(base_size = 17,
base_line_size = 0.5) +
theme(legend.position = "none")
p
View(dbscores_plot)
# Libraries
library(rbacon)
# # # #
# ERMS TANCADA CORE
# # # #
Bacon(core = "ErmsTancada", coredir = "Data/RadiocarbonData/", acc.shape = 1.5, acc.mean = 50, postbomb = 1)
pdf(file = "Figures/RadiocarbonFigs/ErmsTancada_free_surface.pdf")
agedepth(model.only = T)
dev.off()
